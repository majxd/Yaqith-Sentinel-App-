{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Absher Hackathon\n",
        "\n",
        "### YAQITH Sentinel â€“ Behavioral AI Security Agent Project\n",
        "\n",
        "#### Team Name: SANAM\n",
        "#### Team Members:\n",
        "1. Majd Alqarni\n",
        "2. Eman Aldosari\n",
        "3. Arwa Alkibari\n",
        "4. Alwalah Awaji\n",
        "\n",
        "***"
      ],
      "metadata": {
        "id": "Li8JaMRt2Pjz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "#### YAQITH Sentinel â€“ Behavioral AI Security Agent\n",
        "\n",
        "#### YAQITH Sentinel is an AI-powered security agent designed to enhance digital identity protection inside the Absher platform by combining official digital identity with behavioral biometrics.\n",
        "\n",
        "#### The system analyzes multiple real-time signalsâ€”such as device identity, IP address, location, typing patterns, navigation timing, and login historyâ€”to verify whether the user is the legitimate account owner.\n",
        "\n",
        "#### What Problem Does It Solve?\n",
        "\n",
        "#### Traditional authentication (password, OTP, biometrics) can still be bypassed through identity theft or device spoofing.\n",
        "\n",
        "#### YAQITH adds a second behavioral layer that is extremely difficult to fake, providing continuous and intelligent authentication.\n",
        "\n",
        "#### How It Works\n",
        "\n",
        "#### The agent performs three core functions:\n",
        "\n",
        "#### Data Collection Device type & browser\n",
        "#### IP address & location\n",
        "\n",
        "#### Login timestamps\n",
        "\n",
        "#### Behavioral signals (typing speed, navigation rhythm, touch patterns)\n",
        "\n",
        "#### Anomaly Detection\n",
        "#### A lightweight ML model analyzes the userâ€™s normal behavior and detects unusual activity.\n",
        "\n",
        "#### Risk Scoring & Action\n",
        "#### Based on the risk score:\n",
        "\n",
        "####    1. Low risk: seamless login\n",
        "\n",
        "####    2. Medium risk: request additional verification\n",
        "\n",
        "####    3. High risk: block or escalate the session\n",
        "\n",
        "#### Key Features Real-time behavioral authentication\n",
        "\n",
        "####    1. Detects suspicious logins with high accuracy\n",
        "\n",
        "####    2. Privacy-preserving (anonymized behavior patterns)\n",
        "\n",
        "####    3. Adds security without affecting user experience"
      ],
      "metadata": {
        "id": "av2OqVuv30nw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Importing Packages & Columns Identification"
      ],
      "metadata": {
        "id": "aglAQw4e9aFM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6KDT3VzvzzQ"
      },
      "outputs": [],
      "source": [
        "# Importing all necessary packages for ML Model\n",
        "\n",
        "import os\n",
        "import json\n",
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the Dataset\n",
        "DATA_PATH = \"yaqith_sentinel_synthetic_logins_All.xlsx\"\n"
      ],
      "metadata": {
        "id": "z-vgSeFp6JAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Folder & File\n",
        "MODEL_DIR = \"/content/models\"\n",
        "MODEL_PATH = os.path.join(MODEL_DIR, \"risk_model_pipeline.joblib\")\n",
        "FEATURES_PATH = os.path.join(MODEL_DIR, \"yaqith_features.json\")"
      ],
      "metadata": {
        "id": "DKGsjz6Q6K4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Numeric Columns\n",
        "NUMERIC_FEATURES = [\n",
        "    \"is_vpn\",\n",
        "    \"is_new_device\",\n",
        "    \"is_new_city\",\n",
        "    \"distance_from_last_login_km\",\n",
        "    \"hour_of_day\",\n",
        "    \"weekday\",\n",
        "    \"failed_logins_last_24h\",\n",
        "    \"typing_speed_cps\",\n",
        "    \"nav_pattern_similarity\",\n",
        "    \"session_duration_sec\",\n",
        "    \"past_compromised_account\",\n",
        "]\n",
        "\n",
        "# Categorical Columns\n",
        "CATEGORICAL_FEATURES = [\n",
        "    \"device_type\",\n",
        "    \"city\",\n",
        "    \"country\",\n",
        "]\n",
        "\n",
        "# Target Column\n",
        "TARGET_COL = \"is_attack_label\""
      ],
      "metadata": {
        "id": "EbcEtToU76IR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Dataset Loading"
      ],
      "metadata": {
        "id": "OCIh75kL9biF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(path: str) -> pd.DataFrame:\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„Ù: {path}\")\n",
        "    df = pd.read_excel(path)\n",
        "    return df\n",
        "\n",
        "\n",
        "def preprocess(df: pd.DataFrame) -> pd.DataFrame:\n",
        "\n",
        "    required_cols = NUMERIC_FEATURES + CATEGORICAL_FEATURES + [TARGET_COL]\n",
        "    missing = [col for col in required_cols if col not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Ù‡Ø°Ù‡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù†Ø§Ù‚ØµØ© ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {missing}\")\n",
        "\n",
        "    df_proc = df.copy()\n",
        "\n",
        "    # Convert numeric columns to numbers\n",
        "    for col in NUMERIC_FEATURES + [TARGET_COL]:\n",
        "        df_proc[col] = pd.to_numeric(df_proc[col], errors=\"coerce\")\n",
        "\n",
        "    # Drop All the rows that have (NA)\n",
        "    df_proc = df_proc.dropna(subset=required_cols)\n",
        "\n",
        "    # Ensure that the (TARGET_COL) in interger format\n",
        "    df_proc[TARGET_COL] = df_proc[TARGET_COL].astype(int)\n",
        "\n",
        "    return df_proc\n"
      ],
      "metadata": {
        "id": "h9dvDacF6yLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Building Model Pipeline"
      ],
      "metadata": {
        "id": "pqVZGpHs_ByI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model_pipeline() -> Pipeline:\n",
        "\n",
        "    # numeric = passthrough, categorical = OneHot\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", \"passthrough\", NUMERIC_FEATURES),\n",
        "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), CATEGORICAL_FEATURES),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    rf = RandomForestClassifier(\n",
        "        n_estimators=200,\n",
        "        max_depth=None,\n",
        "        random_state=42,\n",
        "        class_weight=\"balanced\",\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "\n",
        "    pipeline = Pipeline(\n",
        "        steps=[\n",
        "            (\"preprocessor\", preprocessor),\n",
        "            (\"model\", rf),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return pipeline\n"
      ],
      "metadata": {
        "id": "tLXyZc-u6lsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Model Training & Performance Evaluation"
      ],
      "metadata": {
        "id": "dZNVSote_Xou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(df: pd.DataFrame) -> Pipeline:\n",
        "\n",
        "    X = df[NUMERIC_FEATURES + CATEGORICAL_FEATURES]\n",
        "    y = df[TARGET_COL]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X,\n",
        "        y,\n",
        "        test_size=0.25,\n",
        "        random_state=42,\n",
        "        stratify=y,\n",
        "    )\n",
        "\n",
        "    pipeline = build_model_pipeline()\n",
        "\n",
        "    print(\"ğŸš€ Training model...\")\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "\n",
        "    print(\"\\n=== Confusion Matrix ===\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "    print(\"\\n=== Classification Report ===\")\n",
        "    print(classification_report(y_test, y_pred, digits=3))\n",
        "\n",
        "    return pipeline\n"
      ],
      "metadata": {
        "id": "ZhzRU--H66KI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Store The Pipeline & Features Info"
      ],
      "metadata": {
        "id": "uBRFJBKaAZIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_artifacts(pipeline: Pipeline) -> None:\n",
        "\n",
        "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "    joblib.dump(pipeline, MODEL_PATH)\n",
        "    print(f\"\\nâœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù€ pipeline ÙÙŠ: {MODEL_PATH}\")\n",
        "\n",
        "    with open(FEATURES_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(\n",
        "            {\n",
        "                \"numeric_features\": NUMERIC_FEATURES,\n",
        "                \"categorical_features\": CATEGORICAL_FEATURES,\n",
        "                \"target\": TARGET_COL,\n",
        "            },\n",
        "            f,\n",
        "            ensure_ascii=False,\n",
        "            indent=2,\n",
        "        )\n",
        "    print(f\"âœ… ØªÙ… Ø­ÙØ¸ ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙÙŠ: {FEATURES_PATH}\")"
      ],
      "metadata": {
        "id": "a4Bdad7S_rFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Main Function"
      ],
      "metadata": {
        "id": "iVJPWiXaAnXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    print(\"1) Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...\")\n",
        "    df = load_data(DATA_PATH)\n",
        "\n",
        "    print(\"2) ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...\")\n",
        "    df_proc = preprocess(df)\n",
        "    print(f\"Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ: {len(df_proc)}\")\n",
        "\n",
        "    print(\"3) ØªØ¯Ø±ÙŠØ¨ ÙˆØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…ÙˆØ¯Ù„...\")\n",
        "    pipeline = train_and_evaluate(df_proc)\n",
        "\n",
        "    print(\"4) Ø­ÙØ¸ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª...\")\n",
        "    save_artifacts(pipeline)\n",
        "\n",
        "    print(\"\\nğŸ‰ Ø¬Ø§Ù‡Ø²: ØªÙ… ØªØ¯Ø±ÙŠØ¨ ÙˆØ­ÙØ¸ Ù…ÙˆØ¯Ù„ YAQITH Sentinel Ø¨Ù†Ø¬Ø§Ø­.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvPDgSyDAnnF",
        "outputId": "c0750d39-5027-4493-89a0-33a7b1556a53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1) Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...\n",
            "2) ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...\n",
            "Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ: 2300\n",
            "3) ØªØ¯Ø±ÙŠØ¨ ÙˆØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…ÙˆØ¯Ù„...\n",
            "ğŸš€ Training model...\n",
            "\n",
            "=== Confusion Matrix ===\n",
            "[[343  29]\n",
            " [137  66]]\n",
            "\n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.715     0.922     0.805       372\n",
            "           1      0.695     0.325     0.443       203\n",
            "\n",
            "    accuracy                          0.711       575\n",
            "   macro avg      0.705     0.624     0.624       575\n",
            "weighted avg      0.708     0.711     0.677       575\n",
            "\n",
            "4) Ø­ÙØ¸ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª...\n",
            "\n",
            "âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù€ pipeline ÙÙŠ: /content/models/risk_model_pipeline.joblib\n",
            "âœ… ØªÙ… Ø­ÙØ¸ ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙÙŠ: /content/models/yaqith_features.json\n",
            "\n",
            "ğŸ‰ Ø¬Ø§Ù‡Ø²: ØªÙ… ØªØ¯Ø±ÙŠØ¨ ÙˆØ­ÙØ¸ Ù…ÙˆØ¯Ù„ YAQITH Sentinel Ø¨Ù†Ø¬Ø§Ø­.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Importing Packages & Identification"
      ],
      "metadata": {
        "id": "JQGhxA0zBeXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing all necessary packages for AI Agent\n",
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Literal, List, Dict, Any\n",
        "\n",
        "import joblib\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "LP_F0IFMCAHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ActionType = Literal[\"allow\", \"step_up\", \"block\"]\n",
        "RiskLevelType = Literal[\"low\", \"medium\", \"high\"]"
      ],
      "metadata": {
        "id": "s3BJXR77DTsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Login Event Identification"
      ],
      "metadata": {
        "id": "xt7haj6DDfP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class LoginEvent:\n",
        "    event_id: int\n",
        "    user_id: int\n",
        "    device_type: str\n",
        "    device_id: str\n",
        "    city: str\n",
        "    country: str\n",
        "    is_vpn: int\n",
        "    is_new_device: int\n",
        "    is_new_city: int\n",
        "    distance_from_last_login_km: float\n",
        "    hour_of_day: int\n",
        "    weekday: int\n",
        "    failed_logins_last_24h: int\n",
        "    typing_speed_cps: float\n",
        "    nav_pattern_similarity: float\n",
        "    session_duration_sec: float\n",
        "    past_compromised_account: int\n",
        "\n",
        "    @classmethod\n",
        "    def from_row(cls, row: pd.Series) -> \"LoginEvent\":\n",
        "        \"\"\"Ø¥Ù†Ø´Ø§Ø¡ LoginEvent Ù…Ù† Ø³Ø·Ø± DataFrame.\"\"\"\n",
        "        return cls(\n",
        "            event_id=int(row[\"event_id\"]),\n",
        "            user_id=int(row[\"user_id\"]),\n",
        "            device_type=str(row[\"device_type\"]),\n",
        "            device_id=str(row[\"device_id\"]),\n",
        "            city=str(row[\"city\"]),\n",
        "            country=str(row[\"country\"]),\n",
        "            is_vpn=int(row[\"is_vpn\"]),\n",
        "            is_new_device=int(row[\"is_new_device\"]),\n",
        "            is_new_city=int(row[\"is_new_city\"]),\n",
        "            distance_from_last_login_km=float(row[\"distance_from_last_login_km\"]),\n",
        "            hour_of_day=int(row[\"hour_of_day\"]),\n",
        "            weekday=int(row[\"weekday\"]),\n",
        "            failed_logins_last_24h=int(row[\"failed_logins_last_24h\"]),\n",
        "            typing_speed_cps=float(row[\"typing_speed_cps\"]),\n",
        "            nav_pattern_similarity=float(row[\"nav_pattern_similarity\"]),\n",
        "            session_duration_sec=float(row[\"session_duration_sec\"]),\n",
        "            past_compromised_account=int(row[\"past_compromised_account\"]),\n",
        "        )"
      ],
      "metadata": {
        "id": "Mn40N3R5Dfbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Security Decision Identification"
      ],
      "metadata": {
        "id": "yQMc705CDn5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This will be the output of the AI Agent after evaluating the Login Event\n",
        "@dataclass\n",
        "class SecurityDecision:\n",
        "    action: ActionType            # \"allow\" / \"step_up\" / \"block\"\n",
        "    risk_score: float             # Value between 0 and 1\n",
        "    risk_level: RiskLevelType     # \"low\" / \"medium\" / \"high\"\n",
        "    reasons: List[str]            #  Reasons behind the decision\n",
        "    metadata: Dict[str, Any]      #  (user_id, device_id, city, ...)"
      ],
      "metadata": {
        "id": "ao_Y4uZODoLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. YAQITH Sentinel Agent Identification"
      ],
      "metadata": {
        "id": "UJURJLm2F76U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUMERIC_FEATURES + CATEGORICAL_FEATURES"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AnRbtQsF0I7",
        "outputId": "9ac47532-aad1-4879-f8dd-a82bb8f8d63f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['is_vpn',\n",
              " 'is_new_device',\n",
              " 'is_new_city',\n",
              " 'distance_from_last_login_km',\n",
              " 'hour_of_day',\n",
              " 'weekday',\n",
              " 'failed_logins_last_24h',\n",
              " 'typing_speed_cps',\n",
              " 'nav_pattern_similarity',\n",
              " 'session_duration_sec',\n",
              " 'past_compromised_account',\n",
              " 'device_type',\n",
              " 'city',\n",
              " 'country']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class YAQITHSentinelAgent:\n",
        "    \"\"\"\n",
        "    Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø£Ù…Ù†ÙŠ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ (AI Agent):\n",
        "    - ÙŠØ³ØªÙ‚Ø¨Ù„ LoginEvent\n",
        "    - ÙŠØ¨Ù†ÙŠ Features Ø¨Ù†ÙØ³ Ø´ÙƒÙ„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨\n",
        "    - ÙŠØ³ØªØ®Ø¯Ù… Ø§Ù„Ù€ pipeline Ù„Ø­Ø³Ø§Ø¨ Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø§Ù„Ù‡Ø¬ÙˆÙ…\n",
        "    - ÙŠÙ‚Ø±Ø± Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ (allow / step_up / block)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_path: str = \"/content/models/risk_model_pipeline.joblib\",\n",
        "        low_to_medium_threshold: float = 0.3,\n",
        "        medium_to_high_threshold: float = 0.7,\n",
        "    ) -> None:\n",
        "        self.model_path = model_path\n",
        "        self.low_to_medium_threshold = low_to_medium_threshold\n",
        "        self.medium_to_high_threshold = medium_to_high_threshold\n",
        "\n",
        "        try:\n",
        "            self.pipeline = joblib.load(model_path)\n",
        "            print(f\"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù€ pipeline Ù…Ù†: {model_path}\")\n",
        "        except FileNotFoundError:\n",
        "            self.pipeline = None\n",
        "            print(\n",
        "                f\"[WARNING] Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {model_path}. \"\n",
        "                f\"Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‚ÙˆØ§Ø¹Ø¯ Ø¨Ø³ÙŠØ·Ø© Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø®Ø§Ø·Ø± (rule-based).\"\n",
        "            )\n",
        "\n",
        "    # --------- Ø¨Ù†Ø§Ø¡ Features Ù„Ù„Ù€ pipeline ---------\n",
        "\n",
        "    def _build_feature_frame(self, event: LoginEvent) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        ÙŠØ­ÙˆÙ„ LoginEvent Ø¥Ù„Ù‰ DataFrame Ø¨ØµÙ ÙˆØ§Ø­Ø¯Ø©.\n",
        "        ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù†ÙØ³ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©:\n",
        "        NUMERIC_FEATURES + CATEGORICAL_FEATURES\n",
        "        \"\"\"\n",
        "\n",
        "        data = {\n",
        "            # numeric\n",
        "            \"is_vpn\": [event.is_vpn],\n",
        "            \"is_new_device\": [event.is_new_device],\n",
        "            \"is_new_city\": [event.is_new_city],\n",
        "            \"distance_from_last_login_km\": [event.distance_from_last_login_km],\n",
        "            \"hour_of_day\": [event.hour_of_day],\n",
        "            \"weekday\": [event.weekday],\n",
        "            \"failed_logins_last_24h\": [event.failed_logins_last_24h],\n",
        "            \"typing_speed_cps\": [event.typing_speed_cps],\n",
        "            \"nav_pattern_similarity\": [event.nav_pattern_similarity],\n",
        "            \"session_duration_sec\": [event.session_duration_sec],\n",
        "            \"past_compromised_account\": [event.past_compromised_account],\n",
        "\n",
        "            # categorical\n",
        "            \"device_type\": [event.device_type],\n",
        "            \"city\": [event.city],\n",
        "            \"country\": [event.country],\n",
        "        }\n",
        "\n",
        "        return pd.DataFrame(data)\n",
        "\n",
        "    # --------- Ø­Ø³Ø§Ø¨ Ø¯Ø±Ø¬Ø© Ø§Ù„Ø®Ø·Ø± ---------\n",
        "\n",
        "    def _predict_risk_ml(self, features: pd.DataFrame) -> float:\n",
        "        \"\"\"ÙŠØ³ØªØ®Ø¯Ù… Ø§Ù„Ù€ pipeline Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù„Ø­Ø³Ø§Ø¨ Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù‡Ø¬ÙˆÙ….\"\"\"\n",
        "        if self.pipeline is None:\n",
        "            raise RuntimeError(\"Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Ù…ÙˆØ°Ø¬ ML Ù…Ø­Ù…Ù‘Ù„ (pipeline is None).\")\n",
        "\n",
        "        proba = self.pipeline.predict_proba(features)[0, 1]\n",
        "        return float(proba)\n",
        "\n",
        "    def _predict_risk_rule_based(self, event: LoginEvent) -> float:\n",
        "        \"\"\"\n",
        "        Ø¨Ø¯ÙŠÙ„ Ø¨Ø³ÙŠØ· Ù„Ùˆ Ù…Ø§ ÙÙŠÙ‡ Ù…ÙˆØ¯Ù„:\n",
        "        ÙŠØ­Ø³Ø¨ risk_score ÙŠØ¯ÙˆÙŠÙ‹Ø§ Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¥Ø´Ø§Ø±Ø§Øª.\n",
        "        \"\"\"\n",
        "        score = 0.0\n",
        "\n",
        "        if event.is_new_device:\n",
        "            score += 0.25\n",
        "        if event.is_new_city:\n",
        "            score += 0.2\n",
        "        if event.is_vpn:\n",
        "            score += 0.2\n",
        "        if event.past_compromised_account:\n",
        "            score += 0.3\n",
        "\n",
        "        if event.failed_logins_last_24h >= 3:\n",
        "            score += 0.2\n",
        "        elif event.failed_logins_last_24h == 2:\n",
        "            score += 0.1\n",
        "\n",
        "        if event.nav_pattern_similarity < 0.5:\n",
        "            score += 0.15\n",
        "        elif event.nav_pattern_similarity < 0.7:\n",
        "            score += 0.1\n",
        "\n",
        "        if event.session_duration_sec < 10:\n",
        "            score += 0.1\n",
        "\n",
        "        return float(max(0.0, min(1.0, score)))\n",
        "\n",
        "    def _get_risk_level(self, risk_score: float) -> RiskLevelType:\n",
        "        \"\"\"ØªØ­ÙˆÙŠÙ„ risk_score Ø¥Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø®Ø·Ø± Ù†ØµÙŠ.\"\"\"\n",
        "        if risk_score < self.low_to_medium_threshold:\n",
        "            return \"low\"\n",
        "        elif risk_score < self.medium_to_high_threshold:\n",
        "            return \"medium\"\n",
        "        return \"high\"\n",
        "\n",
        "    def _decide_action(self, risk_level: RiskLevelType) -> ActionType:\n",
        "        \"\"\"ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ø£Ù…Ù†ÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø®Ø·Ø±.\"\"\"\n",
        "        if risk_level == \"low\":\n",
        "            return \"allow\"\n",
        "        elif risk_level == \"medium\":\n",
        "            return \"step_up\"  # ØªØ­Ù‚Ù‚ Ø¥Ø¶Ø§ÙÙŠ (OTP / FaceID)\n",
        "        return \"block\"       # high risk\n",
        "\n",
        "    def _build_reasons(\n",
        "        self,\n",
        "        event: LoginEvent,\n",
        "        risk_score: float,\n",
        "        risk_level: RiskLevelType,\n",
        "    ) -> List[str]:\n",
        "        \"\"\"ØªØ¬Ù…ÙŠØ¹ Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„Ù‚Ø±Ø§Ø± (Explainability).\"\"\"\n",
        "        reasons: List[str] = []\n",
        "\n",
        "        if event.is_new_device:\n",
        "            reasons.append(\"Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ³Ø¬ÙŠÙ„ Ø¯Ø®ÙˆÙ„ Ù…Ù† Ø¬Ù‡Ø§Ø² Ø¬Ø¯ÙŠØ¯.\")\n",
        "        if event.is_new_city:\n",
        "            reasons.append(\"Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ³Ø¬ÙŠÙ„ Ø¯Ø®ÙˆÙ„ Ù…Ù† Ù…Ø¯ÙŠÙ†Ø© Ø¬Ø¯ÙŠØ¯Ø©.\")\n",
        "        if event.is_vpn:\n",
        "            reasons.append(\"VPN Ø§Ø³ØªØ®Ø¯Ø§Ù…\")\n",
        "        if event.failed_logins_last_24h > 0:\n",
        "            reasons.append(f\"{event.failed_logins_last_24h} Ù…Ø­Ø§ÙˆÙ„Ø§Øª ÙØ§Ø´Ù„Ø© Ø®Ù„Ø§Ù„ Ø¢Ø®Ø± 24 Ø³Ø§Ø¹Ø©.\")\n",
        "        if event.past_compromised_account:\n",
        "            reasons.append(\"Ø§Ù„Ø­Ø³Ø§Ø¨ Ø³Ø¨Ù‚ ÙˆØªÙ… ØªØµÙ†ÙŠÙÙ‡ ÙƒÙ…Ø¹Ø±Ù‘Ø¶ Ù„Ù„Ø§Ø®ØªØ±Ø§Ù‚.\")\n",
        "        if event.nav_pattern_similarity < 0.7:\n",
        "            reasons.append(\"Ù†Ù…Ø· Ø§Ù„ØªÙ†Ù‚Ù„ Ù…Ø®ØªÙ„Ù Ø¹Ù† Ø³Ù„ÙˆÙƒ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø¹ØªØ§Ø¯.\")\n",
        "        if event.session_duration_sec < 10:\n",
        "            reasons.append(\"Ø¬Ù„Ø³Ø© Ø³Ø±ÙŠØ¹Ø© Ø¬Ø¯Ù‹Ø§ØŒ Ù‚Ø¯ ØªØ¯Ù„ Ø¹Ù„Ù‰ Ù†Ø´Ø§Ø· Ø¢Ù„ÙŠ Ø£Ùˆ Ø§Ø®ØªØ¨Ø§Ø± ÙˆØµÙˆÙ„ ÙÙ‚Ø·.\")\n",
        "\n",
        "        if not reasons:\n",
        "            reasons.append(\"Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ù…Ù†Ø®ÙØ¶Ø© ÙˆÙ„Ø§ ØªÙˆØ¬Ø¯ Ø¥Ø´Ø§Ø±Ø§Øª Ø³Ù„ÙˆÙƒÙŠØ© Ù…Ù‚Ù„Ù‚Ø©.\")\n",
        "\n",
        "        reasons.append(f\"Ø¯Ø±Ø¬Ø© Ø§Ù„Ø®Ø·Ø± Ø§Ù„Ù…Ø­Ø³ÙˆØ¨Ø©: {risk_score:.2f} (Ù…Ø³ØªÙˆÙ‰: {risk_level}).\")\n",
        "        return reasons\n",
        "\n",
        "    # --------- Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ---------\n",
        "\n",
        "    def assess_login(self, event: LoginEvent) -> SecurityDecision:\n",
        "        \"\"\"\n",
        "        Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©:\n",
        "        - ØªØ¨Ù†ÙŠ features\n",
        "        - ØªØ­Ø³Ø¨ risk\n",
        "        - ØªØ­Ø¯Ø¯ level + action\n",
        "        - ØªØ±Ø¬Ø¹ Ù‚Ø±Ø§Ø± Ø£Ù…Ù†ÙŠ ÙƒØ§Ù…Ù„.\n",
        "        \"\"\"\n",
        "        features = self._build_feature_frame(event)\n",
        "\n",
        "        if self.pipeline is not None:\n",
        "            risk_score = self._predict_risk_ml(features)\n",
        "        else:\n",
        "            risk_score = self._predict_risk_rule_based(event)\n",
        "\n",
        "        risk_level = self._get_risk_level(risk_score)\n",
        "        action = self._decide_action(risk_level)\n",
        "        reasons = self._build_reasons(event, risk_score, risk_level)\n",
        "\n",
        "        metadata: Dict[str, Any] = {\n",
        "            \"event_id\": event.event_id,\n",
        "            \"user_id\": event.user_id,\n",
        "            \"device_id\": event.device_id,\n",
        "            \"device_type\": event.device_type,\n",
        "            \"city\": event.city,\n",
        "            \"country\": event.country,\n",
        "        }\n",
        "\n",
        "        return SecurityDecision(\n",
        "            action=action,\n",
        "            risk_score=risk_score,\n",
        "            risk_level=risk_level,\n",
        "            reasons=reasons,\n",
        "            metadata=metadata,\n",
        "        )"
      ],
      "metadata": {
        "id": "Ea2kCB-MGJry"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demo to try the YAQITH Sentinel Agent"
      ],
      "metadata": {
        "id": "Zx9GbWHWGxod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ø¯ÙŠÙ…Ùˆ Ø¹Ù…Ù„ÙŠ: Ù†Ø¬Ø±Ø¨ Ø§Ù„ÙˆÙƒÙŠÙ„ Ø¹Ù„Ù‰ Ø³Ø¬Ù„ Ø¹Ø´ÙˆØ§Ø¦ÙŠ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
        "\n",
        "DATA_PATH = \"/content/yaqith_sentinel_synthetic_logins_All.xlsx\"\n",
        "\n",
        "df_demo = pd.read_excel(DATA_PATH)\n",
        "\n",
        "# Ù†Ø®ØªØ§Ø± Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ³Ø¬ÙŠÙ„ Ø¯Ø®ÙˆÙ„ Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©\n",
        "sample_row = df_demo.sample(1).iloc[0]\n",
        "\n",
        "event = LoginEvent.from_row(sample_row)\n",
        "\n",
        "agent = YAQITHSentinelAgent(\n",
        "    model_path=\"/content/models/risk_model_pipeline.joblib\",\n",
        "    low_to_medium_threshold=0.3,\n",
        "    medium_to_high_threshold=0.7,\n",
        ")\n",
        "\n",
        "decision = agent.assess_login(event)\n",
        "\n",
        "print(\"=== Security Decision ===\")\n",
        "print(f\"Action     : {decision.action}\")\n",
        "print(f\"Risk score : {decision.risk_score:.3f}\")\n",
        "print(f\"Risk level : {decision.risk_level}\")\n",
        "\n",
        "print(\"\\nReasons:\")\n",
        "for r in decision.reasons:\n",
        "    print(f\"- {r}\")\n",
        "\n",
        "print(\"\\nMetadata:\")\n",
        "for k, v in decision.metadata.items():\n",
        "    print(f\"- {k}: {v}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PojvC4gQHdgX",
        "outputId": "0f232185-109c-4de7-9ea2-bf25cb276a00"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù€ pipeline Ù…Ù†: /content/models/risk_model_pipeline.joblib\n",
            "=== Security Decision ===\n",
            "Action     : allow\n",
            "Risk score : 0.080\n",
            "Risk level : low\n",
            "\n",
            "Reasons:\n",
            "- Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ù…Ù†Ø®ÙØ¶Ø© ÙˆÙ„Ø§ ØªÙˆØ¬Ø¯ Ø¥Ø´Ø§Ø±Ø§Øª Ø³Ù„ÙˆÙƒÙŠØ© Ù…Ù‚Ù„Ù‚Ø©.\n",
            "- Ø¯Ø±Ø¬Ø© Ø§Ù„Ø®Ø·Ø± Ø§Ù„Ù…Ø­Ø³ÙˆØ¨Ø©: 0.08 (Ù…Ø³ØªÙˆÙ‰: low).\n",
            "\n",
            "Metadata:\n",
            "- event_id: 1321\n",
            "- user_id: 279\n",
            "- device_id: I163\n",
            "- device_type: ios\n",
            "- city: Riyadh\n",
            "- country: Saudi Arabia\n"
          ]
        }
      ]
    }
  ]
}